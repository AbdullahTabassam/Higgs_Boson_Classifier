{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "216abcc4",
   "metadata": {},
   "source": [
    "# <h1><center>Higgs Boson Classification</center></h1>\n",
    "## Part-2\n",
    "### Model training\n",
    "\n",
    "After splitting and scaling the data we are ready to train our models. The models we are going to use in this task are from cuML library as they support GPU for traing and testing the models. We will be using Random forest model and XGBost model, and train these on our complete dataset as well as the dimentionality reduced set and observe the difference in the performance of the models. We will try to tune our models by changing the hyper parameters too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f88c666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the RandomForest classifier from cuML library\n",
    "from cuml.ensemble import RandomForestClassifier as cuRF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ce075a",
   "metadata": {},
   "source": [
    "For our first random forest model we will be using a the default hyper parameters and below is the description of the hyperparameters that we are going to use in our model. \n",
    "\n",
    "1- **n_estimators:** The number of trees in the forest. Increasing this number typically improves the performance of the classifier, but also increases computation time.\n",
    "\n",
    "2- **max_depth:** The maximum depth of each tree in the forest. This parameter controls the complexity of the trees, and increasing it can lead to overfitting.\n",
    "\n",
    "3- **n_bins:** The number of bins used when splitting continuous features. A higher number of bins can lead to better accuracy, but also increases computation time.\n",
    "\n",
    "4- **n_streams:** The number of parallel streams used to build the trees. This parameter can be set to the number of available GPU streams for faster computation.\n",
    "\n",
    "5- **max_samples:** The maximum percentage of samples used to build each tree. This parameter controls the amount of randomness in the forest, and setting it to 1 means that all samples are used to build each tree.\n",
    "\n",
    "6- **split_criterion:** The criterion used to select the best feature to split on at each node. A value of 0 indicates the Gini impurity criterion, while a value of 1 indicates the entropy criterion.\n",
    "\n",
    "7- **random_state:** The random seed used for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2872745",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Default Random Forest params for our first model\n",
    "cu_rf_params = {\n",
    "    'n_estimators'    : 100,\n",
    "    'max_depth'       : 16,\n",
    "    'n_bins'          : 128,\n",
    "    'n_streams'       : 4,\n",
    "    'max_samples'     : 1,\n",
    "    'split_criterion' : 0,\n",
    "    'random_state'    : 123\n",
    "}\n",
    "cu_rf = cuRF(**cu_rf_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a8dbb3",
   "metadata": {},
   "source": [
    "CuML was a possibility for this strategy since we wanted to leverage GPU to improve performance and cut down on processing time. We'll clock our training session as well to keep track of the time. Using the scaled training set, we will train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80a291fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 35s, sys: 254 ms, total: 1min 35s\n",
      "Wall time: 26.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cu_rf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3e4795",
   "metadata": {},
   "source": [
    "The trained model is applied to the test data set using the predict function from the random forest library to provide predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b10c977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 57s, sys: 172 ms, total: 2min 57s\n",
      "Wall time: 2min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# using the predict method on test set\n",
    "y_pred = cu_rf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e27686",
   "metadata": {},
   "source": [
    "We can determine how many of the test predictions were accurate by comparing them to the actual outcomes. Utilising the accuracy score function, this may be determined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2d999c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.7331298589706421\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score: ', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a19133c",
   "metadata": {},
   "source": [
    "This model's accuracy of 73% is not dismal. To test if changing the hyperparameters boosts perforance, we may undertake hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777be759",
   "metadata": {},
   "source": [
    "### Hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70ad6be",
   "metadata": {},
   "source": [
    "Our model was previously trained using default parameters; however, we may now change the parameters to see whether we obtain any useful results. \n",
    "\n",
    "Increasing the number of bins in the Random Forest model can improve its ability to capture nonlinear relationships between the features and the target variable, as it allows for more granular splitting of the data. However, this can also increase the risk of overfitting, especially if the data is noisy or the number of samples is small.\n",
    "\n",
    "Increasing the max depth of the trees in the Random Forest model can improve its ability to capture complex interactions between the features and the target variable. However, it can also increase the risk of overfitting, especially if the data is noisy or the number of samples is small.\n",
    "\n",
    "Increasing the number of estimators in the Random Forest model can improve its ability to generalize to new data by reducing the variance of the model. However, this improvement in performance may come at the cost of increased computational complexity and longer training time.\n",
    "\n",
    "We can also change the random state so that model can try to train on a different distribution of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e26d0873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuml Random Forest params\n",
    "cu_rf_params_2 = {\n",
    "    'n_estimators'   : 500, # increased from 100 to 500\n",
    "    'max_depth'      : 20,  # changed from 16 to 20\n",
    "    'n_bins'         : 150, # increased the bins from 128 to 150\n",
    "    'n_streams'      : 4,   # default\n",
    "    'max_samples'    : 1,   # default\n",
    "    'split_criterion': 0,   # default\n",
    "    'random_state'   : 786  # Changed the Random Number Generator seed to try different distribution\n",
    "}\n",
    "cu_rf_2 = cuRF(**cu_rf_params_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6eeefc27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 19s, sys: 2.5 s, total: 9min 21s\n",
      "Wall time: 2min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "trained_model=cu_rf_2.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "86aae410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25min 17s, sys: 1.47 s, total: 25min 18s\n",
      "Wall time: 25min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "y_pred_2 = cu_rf_2.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "249c6d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.7444262504577637\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score: ', accuracy_score(y_test, y_pred_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedb1066",
   "metadata": {},
   "source": [
    "We can observe that altering the hyperparameter values does, to a certain extent, boost efficacy. albeit at the cost of 22 more minutes during the testing process.\n",
    "To evaluate whether the performance changes, let's try a different random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "80893dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 8s, sys: 2.71 s, total: 11min 11s\n",
      "Wall time: 3min 16s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# cuml Random Forest params\n",
    "cu_rf_params_3 = {\n",
    "    'n_estimators'   : 600, # increase no. of trees to 500\n",
    "    'max_depth'      : 20,  # change to 16\n",
    "    'n_bins'         : 180, # change to 128\n",
    "    'n_streams'      : 4,   # CUDA stream to use for parallel processing on GPU, default is 4\n",
    "    'max_samples'    : 1,   # Percentage of input data to be considered for each tree, default is 1\n",
    "    'split_criterion': 0,   # Split algorithm, default is 0 for gini impurity\n",
    "    'random_state'   : 72   # Seed used for Random Number Generator\n",
    "}\n",
    "cu_rf_3 = cuRF(**cu_rf_params_3)\n",
    "cu_rf_3.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4dd2ed2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31min 48s, sys: 1.14 s, total: 31min 49s\n",
      "Wall time: 31min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred_3 = cu_rf_3.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "33262cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.7445030808448792\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score: ', accuracy_score(y_test, y_pred_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845aba72",
   "metadata": {},
   "source": [
    "The accuracy is almost same as the second experiment and we can assume that without any further processing we would not be able to make any drastic change in the accuracy of the model.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348a75a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "dump( trained_model, 'RF.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092a6435",
   "metadata": {},
   "source": [
    "### Train Random Forest with PCA components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a416212",
   "metadata": {},
   "source": [
    "Now let's train the random forest algorithm with the PCA components and see the effect on the performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76849366",
   "metadata": {},
   "outputs": [],
   "source": [
    "cu_rf_params_pca = {\n",
    "    'n_estimators'    : 500, \n",
    "    'max_depth'       : 20, \n",
    "    'n_bins'          : 150, \n",
    "    'n_streams'       : 4, \n",
    "    'max_samples'     : 1, \n",
    "    'split_criterion' : 0, \n",
    "    'random_state'    : 786\n",
    "}\n",
    "# initailise RF object\n",
    "cu_rf_PCA = cuRF(**cu_rf_params_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0094acf",
   "metadata": {},
   "source": [
    "Fit the PCA components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0958cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 58s, sys: 1.14 s, total: 5min 59s\n",
      "Wall time: 1min 38s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cu_rf_PCA.fit(components, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac688837",
   "metadata": {},
   "source": [
    "Due to the lower amount of features, the training takes less time. To make predictions using the test set, we will also need to convert it into pca components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb5ef21a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.087741</td>\n",
       "      <td>-0.217690</td>\n",
       "      <td>-0.298753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.532698</td>\n",
       "      <td>2.316275</td>\n",
       "      <td>-0.554948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.379118</td>\n",
       "      <td>-1.403355</td>\n",
       "      <td>1.917520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.948131</td>\n",
       "      <td>0.459213</td>\n",
       "      <td>1.628539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.381529</td>\n",
       "      <td>1.415918</td>\n",
       "      <td>-1.045559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2\n",
       "0 -0.087741 -0.217690 -0.298753\n",
       "1  0.532698  2.316275 -0.554948\n",
       "2 -1.379118 -1.403355  1.917520\n",
       "3  0.948131  0.459213  1.628539\n",
       "4  2.381529  1.415918 -1.045559"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_PCA = pca.transform(X_test_scaled)\n",
    "X_test_PCA.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb61b89f",
   "metadata": {},
   "source": [
    "On the test set produced using PCA, the .predict() function will be used to get the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8347384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18min 38s, sys: 541 ms, total: 18min 38s\n",
      "Wall time: 18min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# using the predict method on test set\n",
    "pred_pca = cu_rf_PCA.predict(X_test_PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22f2ab55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.580947995185852\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score: ', accuracy_score(y_test, pred_pca))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738a5f0a",
   "metadata": {},
   "source": [
    "The accuracy has decreased by using the PCA components. Random Forests works better with more number of dimensions and has the ability to perform better parallel computing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf98206",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2311608a",
   "metadata": {},
   "source": [
    "Extreme Gradient Boosting, or XGBoost, is a potent supervised machine learning technique. The most potent algorithms in traditional machine learning are Random Forest and XGBoost, which produce cutting-edge results comparable to those of neural networks. For GPU training, XGBoost with RAPIDS can be utilised. Additionally, XGBoost parallelizes well and trains on large datasets well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "093620e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472c06ec",
   "metadata": {},
   "source": [
    "In XGBoost, a DMatrix is a data structure that is used to represent the input data for training or prediction. It is essentially a memory-optimized format that is designed to efficiently store and access large datasets, and it is used by the XGBoost library for training and predicting with gradient boosting models.\n",
    "\n",
    "The DMatrix format is designed to handle both dense and sparse data, and it supports a variety of input formats. When creating a DMatrix, you typically provide the input data along with any associated labels or weights that are required for training or prediction.\n",
    "\n",
    "The DMatrix format allows for efficient memory usage by storing only the non-zero elements of sparse data, and by using a compressed sparse column (CSC) representation to access this data quickly during training. For dense data, the DMatrix format stores the data in a contiguous block of memory, which can be efficiently accessed during training using SIMD instructions.\n",
    "\n",
    "Once a DMatrix has been created, it can be used to train an XGBoost model using the xgboost.train() function or to make predictions using the xgboost.predict() function. The DMatrix format provides a convenient way to handle large datasets efficiently in XGBoost, which can be especially important when working with high-dimensional data or when training on a large number of samples.\n",
    "\n",
    "#### Converting cuDF data to DMatrix format:\n",
    "\n",
    "Our data is in a cuDF dataframe. we need to convert it to a DMatrix object for GPU optimized XGBoost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6c64e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 109 ms, sys: 37.6 ms, total: 146 ms\n",
      "Wall time: 184 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "d_train = xgb.DMatrix(X_train_scaled, label=y_train)\n",
    "d_validation = xgb.DMatrix(X_test_scaled, label=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4817217",
   "metadata": {},
   "source": [
    "We need to set the parameters for the XGBoost model now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82eb0628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'silent': 1, 'tree_method': 'gpu_hist', 'n_gpus': 1, 'eval_metric': 'auc', 'objective': 'binary:logistic'}\n"
     ]
    }
   ],
   "source": [
    "#  the parameters for the model\n",
    "params = {\n",
    "    #we are not putting any parameters as we just want tio run the model on the default values.\n",
    "}\n",
    "\n",
    "# general params\n",
    "general_params = {'silent': 1} # for verbosity\n",
    "params.update(general_params)\n",
    "\n",
    "# booster params\n",
    "n_gpus = 1  \n",
    "booster_params = {}\n",
    "\n",
    "if n_gpus != 0:\n",
    "    booster_params['tree_method'] = 'gpu_hist'\n",
    "    booster_params['n_gpus'] = n_gpus   \n",
    "params.update(booster_params)\n",
    "\n",
    "# learning task params\n",
    "learning_task_params = {}\n",
    "learning_task_params['eval_metric'] = 'auc'\n",
    "learning_task_params['objective'] = 'binary:logistic'\n",
    "    \n",
    "params.update(learning_task_params)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b040d3",
   "metadata": {},
   "source": [
    "Above code instantiates an XGBoost model by specifying various parameters that control its behavior.\n",
    "\n",
    "The **params** dictionary is used to store the parameters for the model. The first set of parameters are general_params, which includes a single parameter to control the verbosity of the model output.\n",
    "\n",
    "The **booster_params** dictionary contains parameters that are specific to the XGBoost booster, which is the algorithm that is used to build the model. The n_gpus variable controls whether the model will be trained on a GPU or CPU. If **n_gpus** is set to a value greater than 0, then the tree_method parameter is set to 'gpu_hist' and the n_gpus parameter is set to the number of GPUs to use. If n_gpus is set to 0, then the model will be trained on the CPU.\n",
    "\n",
    "The **learning_task_params** dictionary contains parameters that are specific to the learning task, such as the evaluation metric and the objective function. In this case, the evaluation metric is set to 'auc', which is the area under the ROC curve, and the objective function is set to 'binary:logistic', which is used for binary classification problems.\n",
    "\n",
    "Finally, the **params** dictionary is updated with the values from general_params, booster_params, and learning_task_params, and the resulting dictionary is printed to the console. This dictionary can then be used to create an instance of the XGBoost model and to train or make predictions with it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2330cdde",
   "metadata": {},
   "source": [
    "**eval_list** is typically a list of tuples, where each tuple contains a string specifying the evaluation metric to use, and a DMatrix object containing the validation data.\n",
    "\n",
    "In XGBoost, **num_round** refers to the number of boosting rounds to perform during training. Each boosting round corresponds to adding a new tree to the ensemble model. The purpose of num_round is to control the complexity of the model and to prevent overfitting to the training data.\n",
    "\n",
    "Setting num_round too low may result in underfitting, where the model is too simple to capture the patterns in the data. On the other hand, setting num_round too high may result in overfitting, where the model becomes too complex and fits the noise in the training data, resulting in poor generalization performance on new, unseen data.\n",
    "\n",
    "Therefore, num_round should be chosen based on a trade-off between model complexity and generalization performance. Typically, a large value of num_round is chosen and then early stopping is used to prevent overfitting. Early stopping involves monitoring the performance of the model on a validation set after each boosting round, and stopping the training process when the performance on the validation set no longer improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9785c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_list = [(d_validation, 'validation'), (d_train, 'train')]\n",
    "num_round = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad71b4d5",
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:23:59] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
      "Parameters: { \"n_gpus\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation-auc:0.74269\ttrain-auc:0.74290\n",
      "[1]\tvalidation-auc:0.75468\ttrain-auc:0.75489\n",
      "[2]\tvalidation-auc:0.76418\ttrain-auc:0.76437\n",
      "[3]\tvalidation-auc:0.76987\ttrain-auc:0.77006\n",
      "[4]\tvalidation-auc:0.77461\ttrain-auc:0.77488\n",
      "[5]\tvalidation-auc:0.77925\ttrain-auc:0.77950\n",
      "[6]\tvalidation-auc:0.78417\ttrain-auc:0.78443\n",
      "[7]\tvalidation-auc:0.78715\ttrain-auc:0.78743\n",
      "[8]\tvalidation-auc:0.78967\ttrain-auc:0.78994\n",
      "[9]\tvalidation-auc:0.79127\ttrain-auc:0.79161\n",
      "[10]\tvalidation-auc:0.79349\ttrain-auc:0.79384\n",
      "[11]\tvalidation-auc:0.79480\ttrain-auc:0.79515\n",
      "[12]\tvalidation-auc:0.79607\ttrain-auc:0.79641\n",
      "[13]\tvalidation-auc:0.79752\ttrain-auc:0.79787\n",
      "[14]\tvalidation-auc:0.79888\ttrain-auc:0.79922\n",
      "[15]\tvalidation-auc:0.79976\ttrain-auc:0.80014\n",
      "[16]\tvalidation-auc:0.80077\ttrain-auc:0.80116\n",
      "[17]\tvalidation-auc:0.80158\ttrain-auc:0.80197\n",
      "[18]\tvalidation-auc:0.80232\ttrain-auc:0.80273\n",
      "[19]\tvalidation-auc:0.80299\ttrain-auc:0.80342\n",
      "[20]\tvalidation-auc:0.80359\ttrain-auc:0.80405\n",
      "[21]\tvalidation-auc:0.80443\ttrain-auc:0.80491\n",
      "[22]\tvalidation-auc:0.80483\ttrain-auc:0.80535\n",
      "[23]\tvalidation-auc:0.80514\ttrain-auc:0.80565\n",
      "[24]\tvalidation-auc:0.80610\ttrain-auc:0.80663\n",
      "[25]\tvalidation-auc:0.80672\ttrain-auc:0.80727\n",
      "[26]\tvalidation-auc:0.80726\ttrain-auc:0.80785\n",
      "[27]\tvalidation-auc:0.80771\ttrain-auc:0.80830\n",
      "[28]\tvalidation-auc:0.80823\ttrain-auc:0.80886\n",
      "[29]\tvalidation-auc:0.80848\ttrain-auc:0.80911\n",
      "[30]\tvalidation-auc:0.80868\ttrain-auc:0.80934\n",
      "[31]\tvalidation-auc:0.80947\ttrain-auc:0.81015\n",
      "[32]\tvalidation-auc:0.80997\ttrain-auc:0.81068\n",
      "[33]\tvalidation-auc:0.81014\ttrain-auc:0.81086\n",
      "[34]\tvalidation-auc:0.81096\ttrain-auc:0.81169\n",
      "[35]\tvalidation-auc:0.81125\ttrain-auc:0.81200\n",
      "[36]\tvalidation-auc:0.81141\ttrain-auc:0.81217\n",
      "[37]\tvalidation-auc:0.81179\ttrain-auc:0.81257\n",
      "[38]\tvalidation-auc:0.81219\ttrain-auc:0.81299\n",
      "[39]\tvalidation-auc:0.81250\ttrain-auc:0.81332\n",
      "[40]\tvalidation-auc:0.81259\ttrain-auc:0.81341\n",
      "[41]\tvalidation-auc:0.81274\ttrain-auc:0.81358\n",
      "[42]\tvalidation-auc:0.81291\ttrain-auc:0.81376\n",
      "[43]\tvalidation-auc:0.81307\ttrain-auc:0.81391\n",
      "[44]\tvalidation-auc:0.81332\ttrain-auc:0.81418\n",
      "[45]\tvalidation-auc:0.81371\ttrain-auc:0.81459\n",
      "[46]\tvalidation-auc:0.81438\ttrain-auc:0.81529\n",
      "[47]\tvalidation-auc:0.81491\ttrain-auc:0.81584\n",
      "[48]\tvalidation-auc:0.81507\ttrain-auc:0.81602\n",
      "[49]\tvalidation-auc:0.81537\ttrain-auc:0.81633\n",
      "[50]\tvalidation-auc:0.81573\ttrain-auc:0.81671\n",
      "[51]\tvalidation-auc:0.81581\ttrain-auc:0.81680\n",
      "[52]\tvalidation-auc:0.81610\ttrain-auc:0.81710\n",
      "[53]\tvalidation-auc:0.81627\ttrain-auc:0.81730\n",
      "[54]\tvalidation-auc:0.81654\ttrain-auc:0.81759\n",
      "[55]\tvalidation-auc:0.81662\ttrain-auc:0.81768\n",
      "[56]\tvalidation-auc:0.81673\ttrain-auc:0.81781\n",
      "[57]\tvalidation-auc:0.81698\ttrain-auc:0.81807\n",
      "[58]\tvalidation-auc:0.81713\ttrain-auc:0.81822\n",
      "[59]\tvalidation-auc:0.81721\ttrain-auc:0.81831\n",
      "[60]\tvalidation-auc:0.81751\ttrain-auc:0.81863\n",
      "[61]\tvalidation-auc:0.81768\ttrain-auc:0.81879\n",
      "[62]\tvalidation-auc:0.81814\ttrain-auc:0.81927\n",
      "[63]\tvalidation-auc:0.81829\ttrain-auc:0.81944\n",
      "[64]\tvalidation-auc:0.81842\ttrain-auc:0.81959\n",
      "[65]\tvalidation-auc:0.81847\ttrain-auc:0.81966\n",
      "[66]\tvalidation-auc:0.81862\ttrain-auc:0.81981\n",
      "[67]\tvalidation-auc:0.81865\ttrain-auc:0.81985\n",
      "[68]\tvalidation-auc:0.81879\ttrain-auc:0.82001\n",
      "[69]\tvalidation-auc:0.81891\ttrain-auc:0.82016\n",
      "[70]\tvalidation-auc:0.81898\ttrain-auc:0.82023\n",
      "[71]\tvalidation-auc:0.81917\ttrain-auc:0.82044\n",
      "[72]\tvalidation-auc:0.81934\ttrain-auc:0.82062\n",
      "[73]\tvalidation-auc:0.81941\ttrain-auc:0.82069\n",
      "[74]\tvalidation-auc:0.81950\ttrain-auc:0.82079\n",
      "[75]\tvalidation-auc:0.81966\ttrain-auc:0.82096\n",
      "[76]\tvalidation-auc:0.81990\ttrain-auc:0.82120\n",
      "[77]\tvalidation-auc:0.82002\ttrain-auc:0.82134\n",
      "[78]\tvalidation-auc:0.82034\ttrain-auc:0.82167\n",
      "[79]\tvalidation-auc:0.82054\ttrain-auc:0.82187\n",
      "[80]\tvalidation-auc:0.82077\ttrain-auc:0.82211\n",
      "[81]\tvalidation-auc:0.82098\ttrain-auc:0.82232\n",
      "[82]\tvalidation-auc:0.82135\ttrain-auc:0.82270\n",
      "[83]\tvalidation-auc:0.82150\ttrain-auc:0.82286\n",
      "[84]\tvalidation-auc:0.82154\ttrain-auc:0.82291\n",
      "[85]\tvalidation-auc:0.82159\ttrain-auc:0.82296\n",
      "[86]\tvalidation-auc:0.82169\ttrain-auc:0.82309\n",
      "[87]\tvalidation-auc:0.82181\ttrain-auc:0.82322\n",
      "[88]\tvalidation-auc:0.82197\ttrain-auc:0.82340\n",
      "[89]\tvalidation-auc:0.82217\ttrain-auc:0.82361\n",
      "[90]\tvalidation-auc:0.82239\ttrain-auc:0.82385\n",
      "[91]\tvalidation-auc:0.82256\ttrain-auc:0.82401\n",
      "[92]\tvalidation-auc:0.82264\ttrain-auc:0.82412\n",
      "[93]\tvalidation-auc:0.82285\ttrain-auc:0.82434\n",
      "[94]\tvalidation-auc:0.82290\ttrain-auc:0.82440\n",
      "[95]\tvalidation-auc:0.82295\ttrain-auc:0.82447\n",
      "[96]\tvalidation-auc:0.82305\ttrain-auc:0.82458\n",
      "[97]\tvalidation-auc:0.82321\ttrain-auc:0.82476\n",
      "[98]\tvalidation-auc:0.82325\ttrain-auc:0.82481\n",
      "[99]\tvalidation-auc:0.82330\ttrain-auc:0.82488\n",
      "CPU times: user 3.54 s, sys: 116 ms, total: 3.65 s\n",
      "Wall time: 3.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = xgb.train(params, d_train, num_round, eval_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87a7f39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pred = model.predict(d_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80ea2a7",
   "metadata": {},
   "source": [
    "By default, the predictions made by XGBoost are probabilities. To calculate the accuracy score, we can round them to the nearest 0 or 1, then convert them to binary class values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "448f4528",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions = [round(value) for value in model_pred]\n",
    "model_predictions = np.array(model_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "399b13c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.7417985200881958\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score: ', accuracy_score(y_test, model_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e37c86",
   "metadata": {},
   "source": [
    "We can observe that the accuracy of RFC and XGBoost is not much different. We may experiment with other hyperparameters to see if the accuracy improves.\n",
    "An ROC AUC score, which is a better approach to assess the performance of the model, is simple to find with XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "49238f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score:  0.8233003616333008\n"
     ]
    }
   ],
   "source": [
    "print('ROC AUC score: ', roc_auc_score(y_test, model_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31e906d",
   "metadata": {},
   "source": [
    "AUC score of 82% is a good score for this model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a651f4",
   "metadata": {},
   "source": [
    "##### lets try changeing the hyperparameters a bit to see if it makes any difference\n",
    "\n",
    "1-  **silent**:1 : Sets the verbosity of XGBoost to silent mode, meaning that no messages will be printed to the console during training.\n",
    "\n",
    "2-  **tree_method**:**gpu_hist**: Specifies the tree construction method to use during training. In this case,   **gpu_hist** indicates that the GPU histogram algorithm should be used for improved training speed.\n",
    "\n",
    "3-  **n_gpus**: -1: Specifies the number of GPUs to use during training. A value of -1 indicates that all available GPUs should be used.\n",
    "\n",
    "4-  **eval_metric**:**auc**: Specifies the evaluation metric to use during training. In this case,   **auc** indicates that the area under the receiver operating characteristic curve (AUC-ROC) should be used as the evaluation metric.\n",
    "\n",
    "5-  **objective**:**binary:logistic**: Specifies the objective function to optimize during training. In this case,   **binary:logistic** indicates that binary logistic regression should be used.\n",
    "\n",
    "5-  **max_depth**:15 : Specifies the maximum depth of each decision tree in the ensemble model. Increasing this value can increase the model complexity, but may also increase the risk of overfitting.\n",
    "\n",
    "6-  **reg_lambda**:5 : Specifies the L2 regularization parameter for the weights of the decision tree. Increasing this value can help prevent overfitting by penalizing large weights.\n",
    "\n",
    "7-  **scale_pos_weight**:2 : Specifies the scaling factor for the positive class in binary classification problems. This can be useful for imbalanced datasets where one class has many more samples than the other.\n",
    "\n",
    "8-  **gamma**:1: Specifies the minimum loss reduction required to make a further partition on a leaf node of the tree. Increasing this value can help prevent overfitting by reducing the number of splits in the tree.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "108f28eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_2 = {\n",
    "    'silent': 1,\n",
    "    'tree_method': 'gpu_hist',\n",
    "    'n_gpus': -1,\n",
    "    'eval_metric': 'auc', \n",
    "    'objective': 'binary:logistic',\n",
    "    'max_depth': 15,\n",
    "    'reg_lambda': 5,\n",
    "    'scale_pos_weight': 2, \n",
    "    'gamma': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "92b92255",
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:27:26] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
      "Parameters: { \"n_gpus\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation-auc:0.79511\ttrain-auc:0.80975\n",
      "[1]\tvalidation-auc:0.80457\ttrain-auc:0.82164\n",
      "[2]\tvalidation-auc:0.81000\ttrain-auc:0.82940\n",
      "[3]\tvalidation-auc:0.81359\ttrain-auc:0.83514\n",
      "[4]\tvalidation-auc:0.81645\ttrain-auc:0.84004\n",
      "[5]\tvalidation-auc:0.81880\ttrain-auc:0.84426\n",
      "[6]\tvalidation-auc:0.82090\ttrain-auc:0.84860\n",
      "[7]\tvalidation-auc:0.82270\ttrain-auc:0.85209\n",
      "[8]\tvalidation-auc:0.82432\ttrain-auc:0.85544\n",
      "[9]\tvalidation-auc:0.82571\ttrain-auc:0.85867\n",
      "[10]\tvalidation-auc:0.82715\ttrain-auc:0.86210\n",
      "[11]\tvalidation-auc:0.82820\ttrain-auc:0.86471\n",
      "[12]\tvalidation-auc:0.82919\ttrain-auc:0.86798\n",
      "[13]\tvalidation-auc:0.83013\ttrain-auc:0.86943\n",
      "[14]\tvalidation-auc:0.83080\ttrain-auc:0.87063\n",
      "[15]\tvalidation-auc:0.83177\ttrain-auc:0.87251\n",
      "[16]\tvalidation-auc:0.83227\ttrain-auc:0.87373\n",
      "[17]\tvalidation-auc:0.83268\ttrain-auc:0.87454\n",
      "[18]\tvalidation-auc:0.83342\ttrain-auc:0.87763\n",
      "[19]\tvalidation-auc:0.83414\ttrain-auc:0.87984\n",
      "[20]\tvalidation-auc:0.83474\ttrain-auc:0.88258\n",
      "[21]\tvalidation-auc:0.83494\ttrain-auc:0.88308\n",
      "[22]\tvalidation-auc:0.83513\ttrain-auc:0.88376\n",
      "[23]\tvalidation-auc:0.83539\ttrain-auc:0.88457\n",
      "[24]\tvalidation-auc:0.83566\ttrain-auc:0.88559\n",
      "[25]\tvalidation-auc:0.83612\ttrain-auc:0.88671\n",
      "[26]\tvalidation-auc:0.83654\ttrain-auc:0.88934\n",
      "[27]\tvalidation-auc:0.83663\ttrain-auc:0.88966\n",
      "[28]\tvalidation-auc:0.83681\ttrain-auc:0.89030\n",
      "[29]\tvalidation-auc:0.83725\ttrain-auc:0.89249\n",
      "[30]\tvalidation-auc:0.83782\ttrain-auc:0.89515\n",
      "[31]\tvalidation-auc:0.83803\ttrain-auc:0.89682\n",
      "[32]\tvalidation-auc:0.83816\ttrain-auc:0.89722\n",
      "[33]\tvalidation-auc:0.83836\ttrain-auc:0.89773\n",
      "[34]\tvalidation-auc:0.83848\ttrain-auc:0.89811\n",
      "[35]\tvalidation-auc:0.83865\ttrain-auc:0.89900\n",
      "[36]\tvalidation-auc:0.83875\ttrain-auc:0.89936\n",
      "[37]\tvalidation-auc:0.83892\ttrain-auc:0.90053\n",
      "[38]\tvalidation-auc:0.83904\ttrain-auc:0.90143\n",
      "[39]\tvalidation-auc:0.83918\ttrain-auc:0.90196\n",
      "[40]\tvalidation-auc:0.83948\ttrain-auc:0.90426\n",
      "[41]\tvalidation-auc:0.83954\ttrain-auc:0.90456\n",
      "[42]\tvalidation-auc:0.83965\ttrain-auc:0.90506\n",
      "[43]\tvalidation-auc:0.83973\ttrain-auc:0.90533\n",
      "[44]\tvalidation-auc:0.84000\ttrain-auc:0.90643\n",
      "[45]\tvalidation-auc:0.84007\ttrain-auc:0.90725\n",
      "[46]\tvalidation-auc:0.84022\ttrain-auc:0.90811\n",
      "[47]\tvalidation-auc:0.84027\ttrain-auc:0.90842\n",
      "[48]\tvalidation-auc:0.84038\ttrain-auc:0.90910\n",
      "[49]\tvalidation-auc:0.84049\ttrain-auc:0.91079\n",
      "[50]\tvalidation-auc:0.84056\ttrain-auc:0.91132\n",
      "[51]\tvalidation-auc:0.84059\ttrain-auc:0.91168\n",
      "[52]\tvalidation-auc:0.84068\ttrain-auc:0.91219\n",
      "[53]\tvalidation-auc:0.84073\ttrain-auc:0.91273\n",
      "[54]\tvalidation-auc:0.84086\ttrain-auc:0.91429\n",
      "[55]\tvalidation-auc:0.84101\ttrain-auc:0.91483\n",
      "[56]\tvalidation-auc:0.84113\ttrain-auc:0.91612\n",
      "[57]\tvalidation-auc:0.84126\ttrain-auc:0.91784\n",
      "[58]\tvalidation-auc:0.84131\ttrain-auc:0.91815\n",
      "[59]\tvalidation-auc:0.84132\ttrain-auc:0.91857\n",
      "[60]\tvalidation-auc:0.84135\ttrain-auc:0.91873\n",
      "[61]\tvalidation-auc:0.84164\ttrain-auc:0.92061\n",
      "[62]\tvalidation-auc:0.84164\ttrain-auc:0.92105\n",
      "[63]\tvalidation-auc:0.84165\ttrain-auc:0.92126\n",
      "[64]\tvalidation-auc:0.84169\ttrain-auc:0.92176\n",
      "[65]\tvalidation-auc:0.84171\ttrain-auc:0.92192\n",
      "[66]\tvalidation-auc:0.84175\ttrain-auc:0.92213\n",
      "[67]\tvalidation-auc:0.84186\ttrain-auc:0.92248\n",
      "[68]\tvalidation-auc:0.84189\ttrain-auc:0.92287\n",
      "[69]\tvalidation-auc:0.84192\ttrain-auc:0.92330\n",
      "[70]\tvalidation-auc:0.84211\ttrain-auc:0.92379\n",
      "[71]\tvalidation-auc:0.84221\ttrain-auc:0.92485\n",
      "[72]\tvalidation-auc:0.84224\ttrain-auc:0.92516\n",
      "[73]\tvalidation-auc:0.84227\ttrain-auc:0.92582\n",
      "[74]\tvalidation-auc:0.84237\ttrain-auc:0.92645\n",
      "[75]\tvalidation-auc:0.84242\ttrain-auc:0.92730\n",
      "[76]\tvalidation-auc:0.84243\ttrain-auc:0.92840\n",
      "[77]\tvalidation-auc:0.84247\ttrain-auc:0.92876\n",
      "[78]\tvalidation-auc:0.84251\ttrain-auc:0.92928\n",
      "[79]\tvalidation-auc:0.84261\ttrain-auc:0.92952\n",
      "[80]\tvalidation-auc:0.84264\ttrain-auc:0.92970\n",
      "[81]\tvalidation-auc:0.84279\ttrain-auc:0.93063\n",
      "[82]\tvalidation-auc:0.84286\ttrain-auc:0.93186\n",
      "[83]\tvalidation-auc:0.84293\ttrain-auc:0.93271\n",
      "[84]\tvalidation-auc:0.84295\ttrain-auc:0.93316\n",
      "[85]\tvalidation-auc:0.84300\ttrain-auc:0.93372\n",
      "[86]\tvalidation-auc:0.84309\ttrain-auc:0.93500\n",
      "[87]\tvalidation-auc:0.84313\ttrain-auc:0.93540\n",
      "[88]\tvalidation-auc:0.84327\ttrain-auc:0.93668\n",
      "[89]\tvalidation-auc:0.84330\ttrain-auc:0.93700\n",
      "[90]\tvalidation-auc:0.84336\ttrain-auc:0.93762\n",
      "[91]\tvalidation-auc:0.84345\ttrain-auc:0.93795\n",
      "[92]\tvalidation-auc:0.84355\ttrain-auc:0.93873\n",
      "[93]\tvalidation-auc:0.84358\ttrain-auc:0.93942\n",
      "[94]\tvalidation-auc:0.84361\ttrain-auc:0.94003\n",
      "[95]\tvalidation-auc:0.84363\ttrain-auc:0.94071\n",
      "[96]\tvalidation-auc:0.84372\ttrain-auc:0.94104\n",
      "[97]\tvalidation-auc:0.84392\ttrain-auc:0.94231\n",
      "[98]\tvalidation-auc:0.84400\ttrain-auc:0.94299\n",
      "[99]\tvalidation-auc:0.84405\ttrain-auc:0.94343\n",
      "CPU times: user 1min 8s, sys: 464 ms, total: 1min 9s\n",
      "Wall time: 1min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_2 = xgb.train(params_2, d_train, num_round, eval_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0a2cc839",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pred_2 = model_2.predict(d_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "303a2776",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions_2 = [round(value) for value in model_pred_2]\n",
    "model_predictions_2 = np.array(model_predictions_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d3a87707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.7475994229316711\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score: ', accuracy_score(y_test, model_predictions_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bc949799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score:  0.8440521955490112\n"
     ]
    }
   ],
   "source": [
    "print('ROC AUC score: ', roc_auc_score(y_test, model_pred_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c5568d",
   "metadata": {},
   "source": [
    "Looking at the accuracy and AUC score show that model performance is increased a bit but not much. We might need to do further processing of the data to get more accurate results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8ae08b",
   "metadata": {},
   "source": [
    "### XGBoost with PCA componenets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0587de02",
   "metadata": {},
   "source": [
    "Lets try PCA components for XGBoost model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5cfc967c",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train_pca = xgb.DMatrix(components, label=y_train)\n",
    "d_validation_pca = xgb.DMatrix(X_test_PCA, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a2eef0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training settings\n",
    "eval_list_pca = [(d_validation_pca, 'validation'), (d_train_pca, 'train')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f3a3fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_round=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fed981af",
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:46:51] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
      "Parameters: { \"n_gpus\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation-auc:0.59148\ttrain-auc:0.59152\n",
      "[1]\tvalidation-auc:0.59339\ttrain-auc:0.59339\n",
      "[2]\tvalidation-auc:0.59469\ttrain-auc:0.59471\n",
      "[3]\tvalidation-auc:0.59666\ttrain-auc:0.59664\n",
      "[4]\tvalidation-auc:0.59694\ttrain-auc:0.59695\n",
      "[5]\tvalidation-auc:0.59748\ttrain-auc:0.59748\n",
      "[6]\tvalidation-auc:0.59782\ttrain-auc:0.59784\n",
      "[7]\tvalidation-auc:0.59794\ttrain-auc:0.59798\n",
      "[8]\tvalidation-auc:0.59805\ttrain-auc:0.59810\n",
      "[9]\tvalidation-auc:0.59833\ttrain-auc:0.59840\n",
      "[10]\tvalidation-auc:0.59837\ttrain-auc:0.59846\n",
      "[11]\tvalidation-auc:0.59847\ttrain-auc:0.59859\n",
      "[12]\tvalidation-auc:0.59857\ttrain-auc:0.59871\n",
      "[13]\tvalidation-auc:0.59863\ttrain-auc:0.59881\n",
      "[14]\tvalidation-auc:0.59866\ttrain-auc:0.59887\n",
      "[15]\tvalidation-auc:0.59870\ttrain-auc:0.59893\n",
      "[16]\tvalidation-auc:0.59872\ttrain-auc:0.59897\n",
      "[17]\tvalidation-auc:0.59873\ttrain-auc:0.59901\n",
      "[18]\tvalidation-auc:0.59874\ttrain-auc:0.59903\n",
      "[19]\tvalidation-auc:0.59875\ttrain-auc:0.59905\n",
      "[20]\tvalidation-auc:0.59880\ttrain-auc:0.59913\n",
      "[21]\tvalidation-auc:0.59879\ttrain-auc:0.59917\n",
      "[22]\tvalidation-auc:0.59880\ttrain-auc:0.59919\n",
      "[23]\tvalidation-auc:0.59880\ttrain-auc:0.59921\n",
      "[24]\tvalidation-auc:0.59879\ttrain-auc:0.59924\n",
      "[25]\tvalidation-auc:0.59883\ttrain-auc:0.59928\n",
      "[26]\tvalidation-auc:0.59883\ttrain-auc:0.59931\n",
      "[27]\tvalidation-auc:0.59883\ttrain-auc:0.59932\n",
      "[28]\tvalidation-auc:0.59884\ttrain-auc:0.59934\n",
      "[29]\tvalidation-auc:0.59883\ttrain-auc:0.59937\n",
      "[30]\tvalidation-auc:0.59883\ttrain-auc:0.59938\n",
      "[31]\tvalidation-auc:0.59882\ttrain-auc:0.59940\n",
      "[32]\tvalidation-auc:0.59882\ttrain-auc:0.59943\n",
      "[33]\tvalidation-auc:0.59882\ttrain-auc:0.59946\n",
      "[34]\tvalidation-auc:0.59881\ttrain-auc:0.59948\n",
      "[35]\tvalidation-auc:0.59882\ttrain-auc:0.59950\n",
      "[36]\tvalidation-auc:0.59881\ttrain-auc:0.59952\n",
      "[37]\tvalidation-auc:0.59881\ttrain-auc:0.59954\n",
      "[38]\tvalidation-auc:0.59881\ttrain-auc:0.59956\n",
      "[39]\tvalidation-auc:0.59881\ttrain-auc:0.59958\n",
      "[40]\tvalidation-auc:0.59880\ttrain-auc:0.59961\n",
      "[41]\tvalidation-auc:0.59880\ttrain-auc:0.59963\n",
      "[42]\tvalidation-auc:0.59880\ttrain-auc:0.59964\n",
      "[43]\tvalidation-auc:0.59881\ttrain-auc:0.59966\n",
      "[44]\tvalidation-auc:0.59880\ttrain-auc:0.59968\n",
      "[45]\tvalidation-auc:0.59880\ttrain-auc:0.59969\n",
      "[46]\tvalidation-auc:0.59881\ttrain-auc:0.59972\n",
      "[47]\tvalidation-auc:0.59880\ttrain-auc:0.59974\n",
      "[48]\tvalidation-auc:0.59881\ttrain-auc:0.59977\n",
      "[49]\tvalidation-auc:0.59881\ttrain-auc:0.59979\n",
      "[50]\tvalidation-auc:0.59881\ttrain-auc:0.59980\n",
      "[51]\tvalidation-auc:0.59880\ttrain-auc:0.59981\n",
      "[52]\tvalidation-auc:0.59880\ttrain-auc:0.59983\n",
      "[53]\tvalidation-auc:0.59880\ttrain-auc:0.59984\n",
      "[54]\tvalidation-auc:0.59880\ttrain-auc:0.59986\n",
      "[55]\tvalidation-auc:0.59879\ttrain-auc:0.59988\n",
      "[56]\tvalidation-auc:0.59879\ttrain-auc:0.59991\n",
      "[57]\tvalidation-auc:0.59879\ttrain-auc:0.59994\n",
      "[58]\tvalidation-auc:0.59879\ttrain-auc:0.59996\n",
      "[59]\tvalidation-auc:0.59879\ttrain-auc:0.59997\n",
      "[60]\tvalidation-auc:0.59878\ttrain-auc:0.59998\n",
      "[61]\tvalidation-auc:0.59879\ttrain-auc:0.59998\n",
      "[62]\tvalidation-auc:0.59878\ttrain-auc:0.59999\n",
      "[63]\tvalidation-auc:0.59879\ttrain-auc:0.60001\n",
      "[64]\tvalidation-auc:0.59879\ttrain-auc:0.60003\n",
      "[65]\tvalidation-auc:0.59878\ttrain-auc:0.60005\n",
      "[66]\tvalidation-auc:0.59878\ttrain-auc:0.60006\n",
      "[67]\tvalidation-auc:0.59878\ttrain-auc:0.60008\n",
      "[68]\tvalidation-auc:0.59878\ttrain-auc:0.60009\n",
      "[69]\tvalidation-auc:0.59877\ttrain-auc:0.60011\n",
      "[70]\tvalidation-auc:0.59876\ttrain-auc:0.60013\n",
      "[71]\tvalidation-auc:0.59876\ttrain-auc:0.60016\n",
      "[72]\tvalidation-auc:0.59875\ttrain-auc:0.60018\n",
      "[73]\tvalidation-auc:0.59874\ttrain-auc:0.60020\n",
      "[74]\tvalidation-auc:0.59873\ttrain-auc:0.60022\n",
      "[75]\tvalidation-auc:0.59873\ttrain-auc:0.60023\n",
      "[76]\tvalidation-auc:0.59873\ttrain-auc:0.60024\n",
      "[77]\tvalidation-auc:0.59873\ttrain-auc:0.60027\n",
      "[78]\tvalidation-auc:0.59873\ttrain-auc:0.60029\n",
      "[79]\tvalidation-auc:0.59873\ttrain-auc:0.60031\n",
      "[80]\tvalidation-auc:0.59873\ttrain-auc:0.60033\n",
      "[81]\tvalidation-auc:0.59872\ttrain-auc:0.60034\n",
      "[82]\tvalidation-auc:0.59872\ttrain-auc:0.60037\n",
      "[83]\tvalidation-auc:0.59872\ttrain-auc:0.60038\n",
      "[84]\tvalidation-auc:0.59872\ttrain-auc:0.60039\n",
      "[85]\tvalidation-auc:0.59871\ttrain-auc:0.60042\n",
      "[86]\tvalidation-auc:0.59870\ttrain-auc:0.60043\n",
      "[87]\tvalidation-auc:0.59870\ttrain-auc:0.60045\n",
      "[88]\tvalidation-auc:0.59870\ttrain-auc:0.60047\n",
      "[89]\tvalidation-auc:0.59869\ttrain-auc:0.60048\n",
      "[90]\tvalidation-auc:0.59869\ttrain-auc:0.60049\n",
      "[91]\tvalidation-auc:0.59869\ttrain-auc:0.60050\n",
      "[92]\tvalidation-auc:0.59870\ttrain-auc:0.60052\n",
      "[93]\tvalidation-auc:0.59870\ttrain-auc:0.60054\n",
      "[94]\tvalidation-auc:0.59869\ttrain-auc:0.60057\n",
      "[95]\tvalidation-auc:0.59870\ttrain-auc:0.60060\n",
      "[96]\tvalidation-auc:0.59869\ttrain-auc:0.60062\n",
      "[97]\tvalidation-auc:0.59869\ttrain-auc:0.60065\n",
      "[98]\tvalidation-auc:0.59869\ttrain-auc:0.60067\n",
      "[99]\tvalidation-auc:0.59869\ttrain-auc:0.60069\n",
      "CPU times: user 1.69 s, sys: 116 ms, total: 1.8 s\n",
      "Wall time: 1.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "best_pca = xgb.train(params, d_train_pca, num_round, eval_list_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "36ba6f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_pca = best_pca.predict(d_validation_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "18f12844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score:  0.5986874103546143\n"
     ]
    }
   ],
   "source": [
    "print('ROC AUC score: ', roc_auc_score(y_test, pred_pca))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c7ca74",
   "metadata": {},
   "source": [
    "XGBoost with PCA gave similar results to the RFC model with PCA components and we need to consider more preprocessing or increae the number of pca components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9a8844",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
